{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703acb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata # Normalización de texto\n",
    "import re # Expresiones regulares\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # División de texto\n",
    "from sentence_transformers import SentenceTransformer, util # Modelos de embeddings y utilidades\n",
    "from PyPDF2 import PdfReader # Lectura de PDFs\n",
    "from pprint import pprint # Impresión formateada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8') # elimina acentos\n",
    "    #texto = re.sub(r'[^a-z0-9\\s]', '', texto)  # elimina puntuación\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()  # espacios extra\n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f967ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_patron(texto, etiqueta, patron):\n",
    "    match = re.search(patron, texto, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"{etiqueta.upper()}: {match.group(0).strip()}\"\n",
    "    else:\n",
    "        return f\"{etiqueta.upper()}: No disponible\"\n",
    "\n",
    "def extract_metadata(texto):\n",
    "    metadata = {}\n",
    "    metadata['csj'] = buscar_patron(texto, 'csj', r'CSJ\\s*[^\\n\\.]+')\n",
    "    metadata['corte'] = buscar_patron(texto, 'corte', r'CORTE\\s*[^\\n\\.]+')\n",
    "    metadata['provincia'] = buscar_patron(texto, 'provincia', r'BUENOS AIRES\\s*[^\\n\\.]+')\n",
    "    metadata['firma'] = buscar_patron(texto, 'firma', r'FIRMADO\\s*[^\\n\\.]+')\n",
    "    metadata['parte_actora'] = buscar_patron(texto, 'parte_actora', r'PARTE ACTORA\\s*[^\\n\\.]+')\n",
    "    metadata['parte_demandada'] = buscar_patron(texto, 'parte_demandada', r'PARTE DEMANDADA\\s*[^\\n\\.]+')\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(texto):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = splitter.split_text(texto)\n",
    "    return [\n",
    "        {\n",
    "            \"original_text\": chunk,\n",
    "            \"cleaned_text\": clean_text(chunk)\n",
    "        }\n",
    "        for chunk in chunks\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bce004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/research/lawAI/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "modelo = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def generate_embeddings(corpus):\n",
    "    \"\"\"\n",
    "    Genera embeddings para un corpus de texto.\n",
    "    corpus: {\"original_text\": str, \"cleaned_text\": str}\n",
    "    \"\"\"\n",
    "    original_text = [chunk[\"original_text\"] for chunk in corpus]\n",
    "    return modelo.encode(original_text, convert_to_tensor=True, device='cpu')\n",
    "\n",
    "def generate_embeddings_str(string):\n",
    "    \"\"\"\n",
    "    Genera embeddings para un string de texto.\n",
    "    \"\"\"\n",
    "    return modelo.encode(string), \n",
    "\n",
    "\n",
    "def query_similarity(consulta, embeddings_corpus):\n",
    "    \"\"\"\n",
    "    Calcula la similitud entre una consulta y un corpus de texto.\n",
    "    \"\"\"\n",
    "    embedding_consulta = generate_embeddings_str(consulta)\n",
    "    \n",
    "    scores = util.cos_sim(embedding_consulta, embeddings_corpus)\n",
    "    \n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd652323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path): \n",
    "    reader = PdfReader(pdf_path)\n",
    "    texto = \"\"\n",
    "    for page in reader.pages:\n",
    "        texto += page.extract_text() + \"\\n\"\n",
    "    return texto.strip()\n",
    "\n",
    "def search_sentence_in_pdf(pdf_path, sentence):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        if text and sentence.strip() in text:\n",
    "            return i + 1  # Página donde aparece\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e371edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similitud: 0.29 (página 1) -> csj 6066/2014/rh1 y otros molina, luis omar y otros c/ estado nacional - ministerio de justicia, seguridad social y derechos humanos y otro s/ personal militar y civil de las ffaa y de seg. corte suprema de justicia de la nacion 1vistos los autos: recursos de hecho deducidos por la actora en la causa 'molina, luis omar y otros c/ estado nacional - ministerio \n",
      "similitud: 0.27 (página 1) -> de justicia seguridad social y derechos humanos y otro s/ personal militar y civil de las ffaa y de seg.'; css 55491/2010/1/rh1 'aranda norma nelida y otros c/ min justicia seg y dd hh y otro s/ personal militar y civil de las ffaa y de seg.'; css 68528/2010/1/rh1 'benitez damian y otros c/ min justicia seg y dd hh y otro s/ personal militar \n",
      "similitud: 0.31 (página 1) -> y civil de las ffaa y de seg; css 81217/2011/1/rh1 'mora timoteo y otros c/ ministerio de seguridad y otro s/ , para decidir personal militar y civil de las ffaa y de seg.'\" sobre su procedencia. considerando: que los agravios expresados encuentran adecuada respuesta en los votos concurrentes del tribunal en la causa \"pino\" (fallos: 344:2690), a cuyas \n",
      "similitud: 0.33 (página 1) -> consideraciones y conclusiones corresponde remitir, en lo pertinente, por razon de brevedad. por ello, el tribunal resuelve: 1) hacer lugar a las quejas y declarar procedentes los recursos extraordinarios. 2) revocar parcialmente las sentencias y declarar la inconstitucionalidad del decreto de necesidad y urgencia 679/97. vuelvan los \n",
      "similitud: 0.28 (página None) -> autos principales al tribunal de origen a fin de que, por quien corresponda,buenos aires, 10 de junio de 2025 2dicten un nuevo pronunciamiento de acuerdo a lo expresado. costas por su orden. notifiquese, agreguense las quejas a los principales y remitanse. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/research/lawAI/venv/lib/python3.11/site-packages/sentence_transformers/util.py:57: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  a = torch.tensor(a)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# main\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = 'falloEj2.pdf'\n",
    "    texto=\"\"\n",
    "    \"\"\" with open('falloEj2.pdf', 'r', encoding='utf-8') as archivo:\n",
    "        texto = archivo.read() \"\"\"\n",
    "    texto = extract_text_from_pdf(pdf_path)\n",
    "    texto_limpio = clean_text(texto)\n",
    "    metadatos = extract_metadata(texto_limpio)\n",
    "    chunks = chunk_text(texto)\n",
    "    corpus = chunks  # usamos los fragmentos como corpus\n",
    "    embeddings_corpus = generate_embeddings(corpus)\n",
    "    consulta = \"notificaciones\"\n",
    "    scores = query_similarity(consulta, embeddings_corpus)\n",
    "    for i, score in enumerate(scores[0]):\n",
    "        print(f\"similitud: {score.item():.2f} (página {search_sentence_in_pdf(pdf_path, corpus[i]['original_text'])}) -> {corpus[i]['cleaned_text']} \")\n",
    "    \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
